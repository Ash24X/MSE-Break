{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "8mkpAQOnJZJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "S0bIxZUVJc1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")\n"
      ],
      "metadata": {
        "id": "U5JxmYao_rNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp49fdcNJKHt"
      },
      "outputs": [],
      "source": [
        "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/narcotics_trial2.5x.csv\", skiprows=2)\n",
        "refused = df[\"Refused Question\"]\n",
        "accepted = df[\"Completed Question\"]\n",
        "accepted_list = accepted.to_list()\n",
        "refused_list = refused.to_list()"
      ],
      "metadata": {
        "id": "1ni2QN3AJpqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_embeddings(word: str, sentences: list, tokenizer, model, layer):\n",
        "    embeddings = []\n",
        "    word_tokens = tokenizer.tokenize(word)\n",
        "    model.to(device)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        input_ids = tokens[\"input_ids\"].squeeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**tokens, output_hidden_states=True)\n",
        "\n",
        "        token_embeddings = outputs.hidden_states[layer].squeeze(0)\n",
        "        token_strs = [tokenizer.convert_ids_to_tokens(token_id) for token_id in input_ids.tolist()]\n",
        "\n",
        "        indices = []\n",
        "        i = 0\n",
        "        while i < len(token_strs):\n",
        "            if any(word_token in token_strs[i] for word_token in word_tokens):\n",
        "                matched = True\n",
        "                for j in range(1, len(word_tokens)):\n",
        "                    if i + j >= len(token_strs) or word_tokens[j] not in token_strs[i + j]:\n",
        "                        matched = False\n",
        "                        break\n",
        "                if matched:\n",
        "                    indices.extend(range(i, i + len(word_tokens)))\n",
        "            i += 1\n",
        "\n",
        "        if indices:\n",
        "            word_embedding = token_embeddings[indices].mean(dim=0)\n",
        "            embeddings.append(word_embedding)\n",
        "        else:\n",
        "            print(sentence)\n",
        "            print(tokenizer.tokenize(sentence))\n",
        "\n",
        "    return torch.stack(embeddings) if embeddings else torch.empty(0, device=device)"
      ],
      "metadata": {
        "id": "r-Es0wPuJVU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pca_embeddings(accepted_embeddings, refusal_embeddings):\n",
        "    print(\"Accepted embeddings shape:\", accepted_embeddings.shape)\n",
        "    print(\"Refusal embeddings shape:\", refusal_embeddings.shape)\n",
        "\n",
        "    all_embeddings = torch.vstack((accepted_embeddings, refusal_embeddings))\n",
        "    print(\"All embeddings shape:\", all_embeddings.shape)\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_result = pca.fit_transform(all_embeddings.cpu().numpy())\n",
        "    print(\"PCA shape:\", pca_result.shape)\n",
        "\n",
        "    accepted_pca = pca_result[:len(accepted_embeddings)]\n",
        "    refusal_pca = pca_result[len(accepted_embeddings):]\n",
        "    print(\"Accepted PCA shape:\", accepted_pca.shape)\n",
        "    print(\"Refusal PCA shape:\", refusal_pca.shape)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Plot accepted points with their respective indices\n",
        "    plt.scatter(accepted_pca[:, 0], accepted_pca[:, 1], color=\"blue\", alpha=0.7, label=\"Accepted\")\n",
        "    for i, (x, y) in enumerate(accepted_pca):\n",
        "        plt.text(x, y, f\"A-{i}\", fontsize=8, color=\"blue\")\n",
        "\n",
        "    # Plot refusal points with their respective indices\n",
        "    plt.scatter(refusal_pca[:, 0], refusal_pca[:, 1], color=\"red\", alpha=0.7, label=\"Refusal\")\n",
        "    for i, (x, y) in enumerate(refusal_pca):\n",
        "        plt.text(x, y, f\"R-{i}\", fontsize=8, color=\"red\")\n",
        "\n",
        "    plt.title(\"PCA of Accepted vs. Refusal Embeddings\")\n",
        "    plt.xlabel(\"PCA Component 1\")\n",
        "    plt.ylabel(\"PCA Component 2\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d7CMqLdfJ6Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNfiiw8_Vb5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accepted_embeddings = get_word_embeddings(\" narcotics\", accepted_list, tokenizer, model, layer=15)\n",
        "print(accepted_embeddings.shape)\n",
        "\n",
        "refusal_embeddings = get_word_embeddings(\" narcotics\", refused_list, tokenizer, model, layer=15)\n",
        "print(refusal_embeddings.shape)"
      ],
      "metadata": {
        "id": "1211DWx6JP0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_embeddings(accepted_embeddings, refusal_embeddings)"
      ],
      "metadata": {
        "id": "VGXheaZlKA2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accepted_list[13])\n",
        "print(accepted_list[51])\n",
        "print(accepted_list[13])"
      ],
      "metadata": {
        "id": "p0cPTXz1YoIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(refused_list[31])\n",
        "print(refused_list[19])"
      ],
      "metadata": {
        "id": "AKlMyLBwY9MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [13,14,15,16,17,18]\n",
        "\n",
        "for layer in layers:\n",
        "    accepted_embeddings = get_word_embeddings(\" narcotics\", accepted_list, tokenizer, model, layer=layer)\n",
        "    refusal_embeddings = get_word_embeddings(\" narcotics\", refused_list, tokenizer, model, layer=layer)\n",
        "\n",
        "    print(\"LAYER NUMBER:\", layer)\n",
        "    plot_pca_embeddings(accepted_embeddings, refusal_embeddings)"
      ],
      "metadata": {
        "id": "Zg7R6SSAPyoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing embeddings at certain positions"
      ],
      "metadata": {
        "id": "O_m0lHkOoZJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_embeddings(sentences: list[str], tokenizer, model, layer, pos):\n",
        "  embeddings = []\n",
        "  model.to(device)\n",
        "\n",
        "  for sentence in sentences:\n",
        "      tokens = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "      with torch.no_grad():\n",
        "          outputs = model(**tokens, output_hidden_states=True)\n",
        "\n",
        "      hidden_state = outputs.hidden_states[layer][:, pos, :].squeeze(0)\n",
        "      embeddings.append(hidden_state)\n",
        "\n",
        "\n",
        "  return torch.stack(embeddings) if embeddings else torch.empty(0, device=device)"
      ],
      "metadata": {
        "id": "riG_HzNKoY2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [i for i in range(1, len(model.model.layers))]\n",
        "pos=-3\n",
        "\n",
        "for layer in layers:\n",
        "    accepted_embeddings = get_pos_embeddings(accepted_list, tokenizer, model, layer=layer, pos=pos)\n",
        "    refusal_embeddings = get_pos_embeddings(refused_list, tokenizer, model, layer=layer, pos=pos)\n",
        "\n",
        "    print(\"LAYER NUMBER:\", layer)\n",
        "    plot_pca_embeddings(accepted_embeddings, refusal_embeddings)"
      ],
      "metadata": {
        "id": "_5XDty_5oltR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}